# precision-recall-and-F1-score.
Deep Learning- Precision, Recall, F1 score, True Positive

Precision= take Prediction as a Base. Precision tells us how many of the predicted positives are actually correct.

Recall= Take truth as a Base. Recall tells us how many of the actual positives were correctly predicted.

F1 Score= F1-score tells how good the model is overall by balancing precision and recall. 

This project demonstrates how to evaluate the performance of a binary classification model using standard machine learning metrics in Python. Using a simple example with two classes (Dog and Not a Dog), the project compares ground-truth labels with model predictions to compute and visualize a confusion matrix and generate a detailed classification report. I use scikit-learn for metric calculation and matplotlib/seaborn for visualization, clearly illustrating concepts such as true positives, false positives, precision, recall, and F1-score.

